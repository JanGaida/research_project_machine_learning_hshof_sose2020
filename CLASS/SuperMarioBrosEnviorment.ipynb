{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Logo_fh_hof.svg/2000px-Logo_fh_hof.svg.png\" width=\"250\" style=\"background-color:#FFF\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <font size=\"+4\"><i><u>Q-Learning mit 'Super Mario Bros'</u></i></font><br><br>\n",
    "    <font>Seminararbeit der Vorlesung <b>Angewandtes Maschinelles Lernen</b> an der <b>Hochschule für angewande Wissenschaften Hof</b> des <b>Sommersemesters 2020</b>.</font>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Inhaltsverzeichnis<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Parameter-&amp;-Hilfsunktionen\" data-toc-modified-id=\"Parameter-&amp;-Hilfsunktionen-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameter &amp; Hilfsunktionen</a></span></li><li><span><a href=\"#SuperMarioBrosEnviorment\" data-toc-modified-id=\"SuperMarioBrosEnviorment-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>SuperMarioBrosEnviorment</a></span></li><li><span><a href=\"#RewardRecord\" data-toc-modified-id=\"RewardRecord-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>RewardRecord</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T22:01:48.936272Z",
     "start_time": "2020-04-27T22:01:48.862597Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
    "\n",
    "import uuid\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter & Hilfsunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T22:01:48.955848Z",
     "start_time": "2020-04-27T22:01:48.952257Z"
    }
   },
   "outputs": [],
   "source": [
    "global _GYM_ENV_ID\n",
    "global _GYM_ACTIONS\n",
    "global _MONITOR_RECORD_EVERY\n",
    "\n",
    "# Defaults:\n",
    "_GYM_ENV_ID = 'SuperMarioBros-v0'\n",
    "_GYM_ACTIONS = SIMPLE_MOVEMENT\n",
    "_MONITOR_RECORD_EVERY = 1\n",
    "\n",
    "print(\"SuperMarioBrosEnviorment-Parameter auf Default-Werte gestetz ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T22:01:49.039101Z",
     "start_time": "2020-04-27T22:01:48.957422Z"
    }
   },
   "outputs": [],
   "source": [
    "def should_record(current_run):\n",
    "    \"\"\"Gibt True zurück wenn der Run durch den Monitor aufgenommen werden soll; False wenn nicht.\"\"\"\n",
    "    global _MONITOR_RECORD_EVERY\n",
    "    return current_run % _MONITOR_RECORD_EVERY == 0\n",
    "\n",
    "def get_reduced_actionset():\n",
    "    \"\"\"Gibt die Indicies für einen stark reduzierten Actionspace zurück\"\"\"\n",
    "    global _GYM_ACTIONS\n",
    "    if _GYM_ACTIONS == SIMPLE_MOVEMENT: return [1, 2, 5] # { ['right'], ['right', 'A'], ['A'] }\n",
    "    elif _GYM_ACTIONS == COMPLEX_MOVEMENT: return [1, 2, 5, 6] # { ['right'], ['right', 'A'], ['A'], ['left'] }\n",
    "    elif _GYM_ACTIONS == RIGHT_ONLY: return [1, 2] # { ['right'], ['right', 'A'] }\n",
    "    else: raise Error('Unkown Movementset \\\"{}\\\".'.format(_GYM_ACTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T21:05:42.911953Z",
     "start_time": "2020-04-27T21:05:42.901751Z"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuperMarioBrosEnviorment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo-Beschreibung Enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-27T23:07:34.470Z"
    }
   },
   "outputs": [],
   "source": [
    "class SuperMarioBrosEnviorment(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Init\"\"\"\n",
    "        global _GYM_ENV_ID\n",
    "        global _GYM_ACTIONS\n",
    "        global _MONITOR_RECORD_EVERY\n",
    "        \n",
    "        super(SuperMarioBrosEnviorment, self).__init__()\n",
    "        \n",
    "        print(\"Initialisieren SuperMarioBrosEnviorment mit Parameter ...\\n... ID: {}\\n... ACTIONS: {}\\n... RECORD_EVERY: {} ...\".format(_GYM_ENV_ID, _GYM_ACTIONS, _MONITOR_RECORD_EVERY))\n",
    "        \n",
    "        # Make Env und anschließend in JoypadSpace wrappen\n",
    "        env = gym.make(_GYM_ENV_ID)\n",
    "        env = JoypadSpace(env, _GYM_ACTIONS)\n",
    "        \n",
    "        # Finaly\n",
    "        self._reward_records = []\n",
    "        self._reward_records_is_empty = True # für das delgieren von [-1]\n",
    "        self._env = env\n",
    "        self.done = False\n",
    "        \n",
    "        print(\"... abgeschlossen ...\")\n",
    "    \n",
    "    \n",
    "    def monitor(self):\n",
    "        \"\"\"Wrapped das Enviorment in einem Monitor, gibt den Video-Output-Ordner zurück\"\"\"\n",
    "        global _RECORDS_BASE_DIR\n",
    "        \n",
    "        print(\"Wrappe Enviormenter in Monitor ...\")\n",
    "        \n",
    "        # Pfad wird einzigartig generiert\n",
    "        video_output_path = '{}/run_{}__{}'.format(_RECORDS_BASE_DIR,\n",
    "                                                  datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"),\n",
    "                                                  uuid.uuid4())\n",
    "        self._env = Monitor(self._env, \n",
    "                            video_output_path,\n",
    "                            video_callable = lambda episode_id: should_record((episode_id-1)), force = False)\n",
    "        \n",
    "        print(\"... Video-Output-Pfad: \\\"{}\\\" ...\".format(video_output_path))\n",
    "        \n",
    "        return video_output_path\n",
    "        \n",
    "    \n",
    "    # Timecritical\n",
    "    def get_reward(self, info, gym_reward, done):\n",
    "        \"\"\"Berrechnet den Reward und gibt ihn zurück\"\"\"\n",
    "        # Erzeuge einen RewardRecord und füge es der List hinzu\n",
    "        try:\n",
    "            rr = RewardRecord(info, self._reward_records[-1])\n",
    "        except IndexError:\n",
    "            if self._reward_records_is_empty:\n",
    "                rr = RewardRecord(info, None)\n",
    "                self._reward_records_is_empty = False\n",
    "            else:\n",
    "                raise Exception(\"Cought IndexError of RewardRecord while it should not have been empty.\")\n",
    "                \n",
    "        self._reward_records.append(rr) \n",
    "        return rr.reward\n",
    "    \n",
    "    \n",
    "    # Timecritical\n",
    "    def step(self, action):\n",
    "        \"\"\"Die Step-Methode eines Enviorments, der Reward wird hier überschrieben\"\"\"\n",
    "        observation, reward, done, info = self._env.step(action)\n",
    "        return observation, self.get_reward(info, reward, done), done, info\n",
    "    \n",
    "    # Timecritical\n",
    "    def reset(self):\n",
    "        \"\"\"Die Reset-Methode eines Enviorments\"\"\"\n",
    "        # Zurücksetzten der RewardRecord's\n",
    "        # Man könnte hier auch das Array abspeichern - das es aber intuitver ist wird mit dem reset 'überschrieben'\n",
    "        self._reward_records = []\n",
    "        self._reward_records_is_empty = True\n",
    "        return self._env.reset()\n",
    "    \n",
    "    # Timecritical\n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"Die Render-Methode eines Enviorments\"\"\"\n",
    "        return self._env.render(mode=mode)\n",
    "    \n",
    "    # Timecritical\n",
    "    def close (self):\n",
    "        \"\"\"Die Close-Methode eines Enviorments\"\"\"\n",
    "        return self._env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T21:40:38.784165Z",
     "start_time": "2020-04-27T21:40:38.777203Z"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RewardRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "+--------------+---------------------------------------------+\n",
    "|   Info-Key   |                 Beschreibung                |\n",
    "+--------------+---------------------------------------------+\n",
    "| coins        | Anzahl der von Mario gesammelten Münzen     |\n",
    "| life         | Anzahl der Leben von Mario, {2,1,0,255}     |\n",
    "| score        | Kumulativer in-game Punktestand             |\n",
    "| status       | Mario's Zustand {'small','tall','fireball'} |\n",
    "| flag_get     | True wenn Mario die Flagge erreicht         |\n",
    "| world        | Aktuele Welt {1,2,3,4,5,6,7,8}              |\n",
    "| stage        | Aktuelle Etage {1,2,3,4}                    |\n",
    "| time         | Aktuell übrige Zeit {400 bis 0}             |\n",
    "| x_pos        | Mario's absolute X-Position                 |\n",
    "| x_pos_screen | Mario's relative X-Position                 |\n",
    "| y_pos        | Mario's absolute Y-Position                 |\n",
    "+--------------+---------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T07:41:34.806383Z",
     "start_time": "2020-04-29T07:41:34.793125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hilfsklasse\n",
    "class RewardRecord:\n",
    "    \"\"\"Hilfsklasse zum bestimmen des Rewards, wird im Enviorment in eine Liste abgespeichert.\"\"\"\n",
    "    \n",
    "    # Timecritical\n",
    "    def __init__(self, info, last_rr = None):\n",
    "        \"\"\"init\"\"\"\n",
    "        \n",
    "        # Variablen aus Info\n",
    "        self.coins = info['coins']\n",
    "        self.life = int(info['life'])\n",
    "        self.score = info['score']\n",
    "        self.status = info['status']\n",
    "        self.time = info['time']\n",
    "        self.x_pos = info['x_pos']\n",
    "        self.y_pos = info['y_pos']\n",
    "        self.flag_get = info['flag_get']\n",
    "        \n",
    "        # Berrechne den Reward nur wenn vorher bereits ein RR vorhanden war\n",
    "        if not last_rr is None:\n",
    "            self.calculate_reward(last_rr)\n",
    "        else:\n",
    "            self.sum_reward = 0\n",
    "            self.reward = 0\n",
    "    \n",
    "    # Timecritical\n",
    "    def calculate_reward(self, last_rr):\n",
    "        \"\"\"Bestimmt den Reward basirenden auf den letzten RewardRecord und diesem\"\"\"\n",
    "        reward = 0\n",
    "        \n",
    "        # Coinbonus\n",
    "        reward += (self.coins - last_rr.coins) * 5\n",
    "        # Lifepenality\n",
    "        if not self.life == last_rr.life:\n",
    "            reward += -150\n",
    "        # Scorebonus\n",
    "        if last_rr.score < self.score:\n",
    "            reward += (self.score - last_rr.score) * .02\n",
    "        # Timepenality\n",
    "        timedif = (last_rr.time - self.time)\n",
    "        if timedif == 1:\n",
    "            reward += -10\n",
    "        # Progresspenality\n",
    "        if not self.x_pos == last_rr.x_pos :\n",
    "            if last_rr.x_pos < self.x_pos:\n",
    "                reward += 10\n",
    "            else:\n",
    "                reward += 5\n",
    "        elif not self.y_pos == last_rr.y_pos:\n",
    "            reward += 5\n",
    "        else:\n",
    "            reward += -20\n",
    "        # clip reward {-150 <-> 150}\n",
    "        if reward >= 0: reward = min(reward, 150)\n",
    "        else: reward = max(reward, -150)\n",
    "        # Flag reward\n",
    "        if self.flag_get:\n",
    "            reward += 500\n",
    "            \n",
    "        self.reward = reward\n",
    "        self.sum_reward = last_rr.sum_reward + reward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Inhaltsverzeichnis",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
